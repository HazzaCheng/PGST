United States General Accounting OfficeGAOOctober 2002 External Version 1Assessing the Reliability of Computer-Processed DataaContentsPrefaceSection 1: IntroductionSection 2: Understanding Data ReliabilityAssessmentPage i GAO-03-273G Assessing Reliabillity23Section 8: ConductingTracing to and from SourceDocuments 24 Using Advanced Electronic Testing 25 ReviewingSelected System Controls 26 Using Data of Undetermined Reliability2728Section 9: Making theSufficiently Reliable Data 29 NotSufficiently Reliable Data 29 Data of Undetermined Reliability3031Section 10: IncludingSufficiently Reliable Data 31Not Sufficiently Reliable Data 31 in the Report Data ofUndetermined Reliability 32Glossary of Technical TermsFigure 1:FiguresFigure 2:Figure 3: Figure 4: Figure 5: Figure 6: Figure 7: Factors toConsider in Making the Decision on Using the Data 1 DecisionProcess for Determining If a Data Reliability Assessment IsRequired 7 Data Reliability Assessment Process 13 The First Stepsof the Assessment 14 The Preliminary Assessment 19 Choosing andConducting Additional Work 23 Making the Final Assessment 28PrefaceComputer-processed data, often from external sources,increasingly underpin audit reports, including evaluations(performance audits) and financial audits. Therefore, thereliability of such data has become more and more important.Historically, computer-processed data have been treated as uniqueevidence. However, these data are simply one form of evidencerelied on, although they may require more technical assessment thanother forms of evidence. In addition, the very nature of theinformation system creating the data allows opportunities forerrors to be introduced by many people.This guidance is intended to demystify the assessment ofcomputerprocessed data. It supplements GAO's "Yellow Book"(Government Auditing Standards, 1994 Revision), which defines thegenerally accepted government auditing standards (GAGAS), andreplaces the earlier GAO guidance, Assessing the Reliability ofComputer-Processed Data (GAO/OP-8.1.3, Sept. 1990).For all types of evidence, various tests are used-sufficiency,competence, and relevance-to assess whether the evidence standardis met. You probably have been using these tests for years and havebecome quite proficient at them. But because assessingcomputer-processed data requires more technical tests, it mayappear that such data are subject to a higher standard of testingthan other evidence. That is not the case. For example, many of thesame tests of sufficiency and relevance are applied to other typesof evidence. But in assessing computer-processed data, the focus ison one test in the evidence standard-competence-which includesvalidity and reliability. Reliability, in turn, includes thecompleteness and accuracy of the data.This guidance, therefore, provides a flexible, risk-basedframework for data reliability assessments that can be geared tothe specific circumstances of each engagement. The framework alsoprovides a structure for planning and reporting, facilitatesbringing the right mix of skills to each engagement, and ensurestimely management buy-in on assessment strategies. The framework isbuilt onmaking use of all existing information about thedata,performing at least a minimal level of datatesting,doing only the amount of work necessary to determinewhether the data are reliable enough for our purposes,maximizing professional judgment, andbringing the appropriate people, including management, tothe table at key decision points.The ultimate goal of the data reliability assessment is todetermine whether you can use the data for your intended purposes.This guidance is designed to help you make an appropriate,defensible assessment in the most efficient manner. With anyrelated questions, call Barbara Johnson, focal point for datareliability issues, at (202) 512-3663, or Barry Seltser, the ActingDirector of GAO's Center for Design, Methods, and Analysis, at(202) 512-3234.Nancy KingsburyManaging Director, Applied Research and MethodsSection 1: IntroductionThis guidance explains what data reliability means and providesa framework for assessing the reliability of computer-processeddata. It begins with the steps in a preliminary assessment, which,in many cases, may be all you need to do to assess reliability.This guidance also helps you decide whether you should follow upthe preliminary assessment with additional work. If so, it explainsthe steps in a final assessment and the actions to take, dependingon the results of your additional work. The ultimate goal indetermining data reliability is to make the following decision: Forour engagement, can we use the data to answer the researchquestion? See figure 1 for an overview of the factors that help toinform that decision. Not all of these factors may be necessary forall engagements.Figure 1: Factors to Consider in Making the Decision on Usingthe DataSource: GAO.In addition, this guidance discusses suggestedlanguage-appropriate under different circumstances-for reportingthe results of your assessment. Finally, it provides detaileddescriptions of all the stages of the assessment, as well as aglossary of technical terms used (see p. 33). An on-line version ofthis guidance, which will include tools that may help you inassessing reliability, is currently being developed. The overallprocess is illustrated in figures 2 (p. 7) and 3 (p. 13).Section 2: Understanding Data ReliabilityData reliability refers to the accuracy and completeness ofcomputerprocessed data, given the intended purposes for use.Computer-processed data include data (1) entered into a computersystem and (2) resulting from computer processing.Computer-processed data can vary in form-from electronic files totables in published reports. The definition of computerprocesseddata is therefore broad. In this guidance, the term data alwaysrefers to computer-processed data.The "Yellow Book" requires that a data reliability assessment beperformed for all data used as support for engagement findings,conclusions, or recommendations.1 This guidance will help you todesign a data reliability assessment appropriate for the purposesof the engagement and then to evaluate the results of theassessment.Data are reliable when they are (1) complete (they contain allof the data elements and records needed for the engagement)2 and(2) accurate (they reflect the data entered at the source or, ifavailable, in the source documents). A subcategory of accuracy isconsistency. Consistency refers to the need to obtain and use datathat are clear and well-defined enough to yield similar results insimilar analyses. For example, if data are entered at multiplesites, inconsistent interpretation of data rules can lead to datathat, taken as a whole, are unreliable. Reliability also means thatfor any computer processing of the data elements used, the resultsare reasonably complete and accurate, meet your intended purposes,and are not subject to inappropriate alteration.Assessments of reliability should be made in the broader contextof the particular characteristics of the engagement and the riskassociated with the possibility of using data of insufficientreliability. Reliability does not mean that computer-processed dataare error-free. Errors are considered acceptable under thesecircumstances: You have assessed the associated risk and found theerrors are not significant enough to cause a reasonable person,aware of the errors, to doubt a finding, conclusion, orrecommendation based on the data.1U.S. General Accounting Office, Government Auditing Standards, GAO/OGC-94-4(Washington, D.C.: June 1994), pp.62-87.2A data element is a unit of information with definableparameters (for example, a Social Security number), sometimesreferred to as a data variable or data field.Page 3 GAO-03-273G Assessing ReliabilityWhile this guidance focuses only on the reliability of data interms of accuracy and completeness, other data qualityconsiderations are just as important. In particular, you shouldalso consider the validity of data. Validity (as used here) refersto whether the data actually represent what you think is beingmeasured. For example, if a data field is named "annual evaluationscore," is this an appropriate measure of a person's jobperformance? Considerations of data validity and reliability issuesshould be addressed early in the engagement, and appropriatetechnical specialists-such as data analysts, statisticians, orinformation technology specialists-should be consulted.Section 3: Deciding If a Data Reliability Assessment IsNecessaryTo decide if a data reliability assessment is necessary, youshould consider certain conditions. The engagement type and planneduse of the data help to determine when you should assess datareliability. See figure 2 for an illustration of the decisionprocess that you should use.Figure 2: Decision Process for Determining If a Data ReliabilityAssessment Is RequiredSource: GAO.Conditions Requiring a Data Reliability AssessmentYou should assess reliability if the data to be analyzed areintended to support the engagement findings, conclusions, orrecommendations. Keep in mind that a finding may include only adescription of the condition, as in a purely descriptive report. Inthe audit plan for the engagement, you should include a briefdiscussion of how you plan to assess data reliability, as well asany limitations that may exist due to shortcomings in the data.Conditions Not Requiring a Data Reliability AssessmentYou do not need to assess reliability if the data are used (1)only as background information or (2) in documents withoutfindings, conclusions, or recommendations. Background informationgenerally sets the stage for reporting the results of an engagementor provides information that puts the results in proper context.Such information could be the size of the program or activity youare reviewing, for example. When you gather background or otherdata, ensure that they are from the best available source(s). Whenyou present the data, cite the source(s) and state that the datawere not assessed.Sometimes, as a best practice, however, you may want to do someassessment of background data. Your judgment of the data'simportance and the reliability of the source, as well as otherengagement factors, can help you determine the extent of such anassessment.Finally, for financial audits and information system reviews,you should not follow this guidance in assessing data reliability.For financial audits, which include financial statement andfinancial-related audits, you should follow the GAO/PCIE FinancialAudit Manual (FAM) and the Federal Information System ControlsAudit Manual (FISCAM). In an information system review, allcontrols in a computer system, for the full range of applicationfunctions and products, are assessed and tested. Such a reviewincludes (1) examining the general and application controls of acomputer system,3 (2) testing whether those controls are beingcomplied with, and(3) testing data produced by the system.4 To design such areview, appropriate to the research question, seek assistance frominformation technology specialists.3General controls refers to the structure, policies, andprocedures-which apply to all or a large segment of anorganization's information systems-that help to ensure properoperation, data integrity, and security. Application controlsrefers to the structure, policies, and procedures that apply toindividual application systems, such as inventory or payroll.4Guidance for carrying out reviews of general and applicationcontrols is provided in theU.S. General Accounting Office, Federal Information SystemControls Audit Manual, GAO/AIMD-12.19.6(Washington, D.C.: Jan. 1999).Section 4: Performing a Data Reliability AssessmentTiming the AssessmentTo perform a data reliability assessment, you need to decide onthe timing-when to perform the assessment-and how to documentit.A data reliability assessment should be performed as early aspossible in the engagement process, preferably during the designphase. The audit plan should reflect data reliability issues andany additional steps that still need to be performed to assess thereliability of critical data. The engagement team generally shouldnot finalize the audit plan or issue a commitment letter until ithas done initial testing and reviewed existing information aboutthe data and the system that produces the data. In addition, theteam should not commit to making conclusions or recommendationsbased on the data unless the team expects to be satisfied with thedata reliability.Documenting the AssessmentAll work performed as part of the data reliability assessmentshould be documented and included in the engagement workpapers.This includes all testing, information review, and interviewsrelated to data reliability. In addition, decisions made during theassessment, including the final assessment of whether the data aresufficiently reliable for the purposes of the engagement, should besummarized and included with the workpapers. These workpapersshould be (1) clear about what steps the team took and whatconclusions they reached and (2) reviewed by staff with appropriateskills or, if needed, technical specialists.Section 5: Viewing the Entire Assessment ProcessThe ultimate goal of the data reliability assessment is todetermine whether you can use the data to answer the researchquestion. The assessment should be performed only for thoseportions of the data that are relevant to the engagement. Theextensiveness of the assessment is driven bythe expected significance of the data to the finalreport,the anticipated risk level of using the data,andthe strength or weakness of any corroboratingevidence.Therefore, the specific assessment process should take intoaccount these factors along with what is learned during the initialstage of the assessment. The process is likely to be different foreach engagement.The overall framework of the process for data reliabilityassessment is shown in figure 3. The framework identifies severalkey stages in the assessment, as well as actions and decisionsexpected as you move through the process. The framework allows youto identify the appropriate mix of assessment steps to fit theparticular needs of your engagement. In most cases, all of theelements in figure 3 would not be necessary in completing theassessment. Specific actions for each stage are discussed insections 6-10.Figure 3: Data Reliability Assessment ProcessSource: GAO.Section 6: Taking the First StepsReviewing Existing InformationThe data reliability process begins with two relatively simplesteps. These steps provide the basis for making a preliminaryassessment of data reliability: (1) a review of related informationand (2) initial testing (see figure 4). In some situations, you mayhave an extremely short time frame for the engagement; this sectionalso provides some advice for this situation.The time required to review related information and performinitial testing will vary, depending on the engagement and theamount of risk involved. As discussed in section 4, these stepsshould take place early in the engagement and include the teammembers, as well as appropriate technical staff.Figure 4: The First Steps of the AssessmentSource: GAO.The first step-a review of existing information-helps you todetermine what is already known about the data and the computerprocessing. The related information you collect can indicate boththe accuracy and completeness of the entry and processing of thedata, as well as how data integrity is maintained. This informationcan be in the form of reports, studies, or interviews withindividuals who are knowledgeable about the data and the system.Sources for related information include GAO, the agency underreview, and others.GAO GAO may already have related information in reports. Thosefrom fiscal year 1995 to the present are available via GAO'sInternet site. This site also provides other useful information:for example, as part of the annual governmentwide consolidatedfinancial audit, GAO's Information Technology Team is involved withreporting on the effectiveness of controls for financialinformation systems at 24 major federal agencies.Agency under ReviewOfficials of the agency or entity under review are aware ofevaluations of their computer data or systems and usually candirect you to both. However, keep in mind that information fromagency officials may be biased. Consider asking appropriatetechnical specialists to help in evaluating this information.Agency information includes Inspector General reports, FederalManagers' Financial Integrity Act reports, Government Performanceand Results Act (GPRA) plans and reports, Clinger-Cohen Actreports, and Chief Information Officer reports. (Some of thisinformation can be found in agency homepages on the Web.)Others Other organizations and users of the data may be sourcesof relevant information. To help you identify these sources, youcan use a variety of databases and other research tools, whichinclude the Congressional Research Service Public Policy LiteratureAbstracts and organizations' Web sites.Performing Initial TestingThe second step-initial testing-can be done by applying logicaltests to electronic data files or hard copy reports. For electronicdata, you use computer programs to test all entries of key dataelements in the entire data file.5 Keep in mind that you only testthose data elements you plan to use for the engagement. You willfind that testing with computer programs often takes less than aday, depending on the complexity of the file. For5 Though an in-depth discussion of quality-assurance practicesto be used in electronic testing and analyses is beyond the scopeof this guidance, it is important to perform appropriate checks toensure that you have obtained the correct file. All too often,analysts receive an incorrect file (an early version or anincomplete file). Appropriate steps would include counting recordsand comparing totals with the responsible agency or entity.Page 15 GAO-03-273G Assessing ReliabilityDealing with Short Time Frameshard copy or summarized data-provided by the audited entity orretrieved from the Internet-you can ask for the electronic datafile used to create the hard copy or summarized data. If you areunable to obtain electronic data, use the hard copy or summarizeddata and, to the extent possible, manually apply the tests to allinstances of key data elements or, if the report or summary isvoluminous, to a sample of them.Whether you have an electronic data file or a hard copy reportor summary, you apply the same types of tests to the data. Thesecan include testing formissing data, either entire records or values of key dataelements;the relationship of one data element toanother;values outside of a designated range; anddates outside valid time frames or in an illogicalprogression.Be sure to keep a log of your testing for inclusion in theengagement workpapers.In some instances, the engagement may have a time frame that istoo short for a complete preliminary assessment, for example, arequest for testimony in 2 weeks. However, given that allengagements are a function of time, as well as scope and resources,limitations in one require balancing the others.Despite a short time frame, you may have time to review existinginformation and carry out testing of data that are critical foranswering a research question, for example: You can questionknowledgeable agency staff about data reliability or reviewexisting GAO or Inspector General reports to quickly gatherinformation about data reliability issues. In addition, electronictesting of critical data elements for obvious errors ofcompleteness and accuracy can generally be done in a short periodof time on all but the most complicated or immense files. From thatreview and testing, you will be able to make a more informeddetermination about whether the data are sufficiently reliable touse for the purposes of the engagement. (See sections 7 and 8 forthe actions to take, depending on your determination.)Section 7: Making the Preliminary AssessmentFactors to Consider in the AssessmentThe preliminary assessment is the first decision point in theassessment process, including the consideration of multiplefactors, a determination of the sufficiency of the data reliabilitywith what is known at this point, and a decision about whetherfurther work is required. You will decide whether the data aresufficiently reliable for the purposes of the engagement, notsufficiently reliable, or as yet undetermined. Keep in mind thatyou are not attesting to the overall reliability of the data ordatabase. You are only determining the reliability of the data asneeded to support the findings, conclusions, or recommendations ofthe engagement. As you gather information and make your judgments,consult appropriate technical specialists for assistance.To make the preliminary assessment of the sufficiency of thedata reliability for the engagement, you should consider allfactors related to aspects of the engagement, as well as assessmentwork performed to this point. As shown in figure 5, these factorsincludethe expected significance of the data in the finalreport,corroborating evidence,level of risk, andthe results of initial assessment work.Figure 5: The Preliminary AssessmentSource: GAO.Expected Significance of In making the preliminary assessment,consider the data in the context of the final report: Will theengagement team depend on the data alone tothe Data in the Final Reportanswer a research question? Will the data be summarized or willdetailed information be required? Is it important to have precisedata, making magnitude of errors an issue?Corroborating Evidence You should consider the extent to whichcorroborating evidence is likely to exist and will independentlysupport your findings, conclusions, or recommendations.Corroborating evidence is independent evidence that supportsinformation in the database. Such evidence, if available, can befound in the form of alternative databases or expert views. It isunique to each engagement, and itsstrength-persuasiveness-varies.For help in deciding the strength or weakness of corroboratingevidence, consider the extent to which the corroboratingevidenceis consistent with the "Yellow Book" standards ofevidence-sufficiency, competence, and relevance;provides crucial support;Level of Riskis drawn from different types of sources-testimonial,documentary, physical, or analytical; andis independent of other sources.Risk is the likelihood that using data of questionablereliability could have significant negative consequences on thedecisions of policymakers and others. To do a risk assessment,consider the following risk conditions:The data could be used to influence legislation, policy,or a program that could have significant impact.The data could be used for significant decisions byindividuals or organizations with an interest in thesubject.The data will be the basis for numbers that are likely tobe widely quoted, for example, "In 1999, the United States owed theUnited Nations about $1.3 billion for the regular and peacekeepingbudgets."The engagement is concerned with a sensitive orcontroversial subject.The engagement has external stakeholders who have takenpositions on the subject.The overall engagement risk is medium or high.The engagement has unique factors that strongly increaserisk.Bear in mind that any one of the conditions may have moreimportance than another, depending on the engagement.Results of Initial Assessment WorkAt this point, as shown in figure 5 (p. 19), the team willalready have performed the initial stage of the data reliabilityassessment. They should have the results from the (1) review of allavailable existing information about the data and the system thatproduced them and (2) initial testing of the critical dataelements. These results should be appropriately documented andreviewed before the team enters into the decision-making phase ofthe preliminary assessment. Because the results will, in whole orin part, provide the evidence that the data are sufficientlyreliable-and therefore competent enough-or not sufficientlyreliable for the purposesOutcomes to Consider in the Assessmentof the engagement, the workpapers should include documentationof the process and results.The results of your combined judgments of the strength ofcorroborating evidence and degree of risk suggest differentassessments. If the corroborating evidence is strong and the riskis low, the data are more likely to be considered sufficientlyreliable for your purposes. If the corroborating evidence is weakand the risk is high, the data are more likely to be considered notsufficiently reliable for your purposes. The overall assessment isa judgment call, which should be made in the context of discussionwith team management and technical specialists.The preliminary assessment categorizes the data as sufficientlyreliable, not sufficiently reliable, or of undeterminedreliability. Each category has implications for the next steps ofthe data reliability assessment.When to Assess Data as Sufficiently Reliable for EngagementPurposesYou can assess the data as sufficiently reliable for engagementpurposes when you conclude the following: Both the review ofrelated information and the initial testing provide assurance that(1) the likelihood of significant errors or incompleteness isminimal and (2) the use of the data would not lead to an incorrector unintentional message. You could have some problems oruncertainties about the data, but they would be minor, given theresearch question and intended use of the data. When thepreliminary assessment indicates that the data are sufficientlyreliable, use the data.When to Assess Data as Not Sufficiently Reliable for EngagementPurposesYou can assess the data as not sufficiently reliable forengagement purposes when you conclude the following: The review ofrelated information or initial testing indicates that (1)significant errors or incompleteness exist in some or all of thekey data elements and (2) using the data would probably lead to anincorrect or unintentional message.When the preliminary assessment indicates that the data are notsufficiently reliable, you should seek evidence from other sources,including (1) alternative computerized data-the reliability ofwhich you should also assess-or (2) original data in the form ofsurveys, case studies, or expert interviews.When to Assess Data as of Undetermined Reliability and ConsiderAdditional WorkYou should coordinate with the requester if seeking evidencefrom other sources does not result in a source of sufficientlyreliable data. Inform the requester that such data, needed torespond to the request, are unavailable. Reach an agreement withthe requester toredefine the research questions to eliminate the need touse the data,end the engagement, oruse the data with appropriate disclaimers.Remember that you-not the requester-are responsible for decidingwhat data to use. If you decide you must use data that you havedetermined are not sufficiently reliable for the purposes of theengagement, make the limitations of the data clear, so thatincorrect or unintentional conclusions will not be drawn. Finally,given that the data you assessed have serious reliabilityweaknesses, you should include this finding in the report andrecommend that the agency take corrective action.You can assess the data as of undetermined reliability when youconclude one of the following:The review of some of the related information or initialtesting raises questions about the data's reliability.The related information or initial testing provides toolittle information to judge reliability.The time or resource constraints limit the extent of theexamination of related information or initial testing.When the preliminary assessment indicates that the reliabilityof the data is undetermined, consider doing additional work todetermine reliability. Section 8 provides guidance on the types ofadditional work to consider, as well as suggestions if noadditional work is feasible.Section 8: Conducting Additional WorkWhen you have determined (through the preliminary assessment)that the data are of undetermined reliability, consider conductingadditional work (see figure 6). A range of additional steps tofurther determine data reliability includes tracing to and fromsource documents, using advanced electronic testing, and reviewingselected system controls. The mix depends on what weaknesses youidentified in the preliminary assessment and the circumstancesspecific to your engagement, such as risk level and corroboratingevidence, as well as other factors. Focus particularly on thoseaspects of the data that pose the greatest potential risk for yourengagement. You should get help from appropriate technicalspecialists to discuss whether additional work is required and tocarry out any part of the additional reliability assessment.Figure 6: Choosing and Conducting Additional WorkSource: GAO.Tracing to and from Source DocumentsTracing a sample of data records to source documents helps youto determine whether the computer data accurately and completelyreflect these documents. In deciding what and how to trace,consider the relative risks to the engagement of overstating orunderstating the conclusions drawn from the data, for example: Onthe one hand, if you are particularly concerned that questionablecases might not have been entered into the computer system and thatas a result, the degree of compliance may be overstated, you shouldconsider tracing from source documents to the database. On theother hand, if you are more concerned that ineligible cases havebeen included in the database and that as a result, the potentialproblems may be understated, you should consider tracing from thedatabase back to source documents.The reason to trace only a sample is because sampling saves timeand cost. To be useful, however, the sample should be random andlarge enough to estimate the error rate within reasonable levels ofprecision. Tracing a random sample will provide the error rate andthe magnitude of errors for the entire data file. It is this errorrate that helps you to determine the data reliability. Generally,every data file will have some degree of error (see example 1 forerror rate and example 2 for magnitude of errors). Consultstatisticians to assist you in selecting the sampling method mostsuited to the engagement.Example 1: According to a random sample, 10 percent of the datarecords have incorrect dates. However, the dates may be off by anaverage of only 3 days. Depending on what the data are used for, 3days may not compromise reliability.Example 2: The value of a data element was incorrectly enteredas $100,000, rather than $1,000,000. The documentation of thedatabase shows that the acceptable range for this data element isbetween $100 and $5,000,000. Therefore, the electronic testing donein the initial testing phase would have confirmed that the value of$100,000 fell within that range. In this case, the error could becaught, not by electronic testing, but only by tracing the data tosource documents.Tracing to Source DocumentsConsider tracing to source documents when (1) the sourcedocuments are available relatively easily or (2) the possiblemagnitude of errors is especially critical.To trace a sample to source documents, match the entered datawith the corresponding data in the source documents. But inattempting to trace entered data back to source documents, severalproblems can arise: Source documents may not be available becausethey were destroyed, were never created, or are not centrallylocated.Several options exist if source documents are not available. Forthose documents never created-for example, when data may be basedon electronic submissions-use interviews to obtain relatedinformation, any corroborating evidence obtained earlier, or areview of the adequacy of system controls.Tracing from Source DocumentsConsider tracing from source documents, instead of or inaddition to tracing a sample to source documents, when you haveconcerns that the data are not complete. To trace a sample fromsource documents, match the source documents with the entered data.Such tracing may be appropriate to determine whether all data arecompletely entered. However, if source documents were never createdor are now missing, you cannot identify the missing data.Using Advanced Electronic TestingAdvanced electronic testing goes beyond the basic electronictesting that you did in initial testing (see section 5). Itgenerally requires specialized computer programs to test forspecific conditions in the data. Such testing can be particularlyhelpful in determining the accuracy and completeness of processingby the application system that produced the data. Consider usingadvanced electronic testing for following up on troubling aspects of the data-such asextremely high values associated with a certain geographiclocation-found in initial testing or while analyzing the data;Reviewing Selected System Controlstesting relationships-cross-tabulation-between dataelements, such as whether data elements follow a skip pattern froma questionnaire; andverifying that computer processing is accurate andcomplete, such as testing a formula used in generating specificdata elements.Depending on what will be tested, this testing can require arange of programming skills-from creating cross-tabulations onrelated data elements to duplicating an intricate automated processwith more advanced programming techniques. Consult appropriatetechnical specialists, as needed.Your review of selected system controls-the underlyingstructures and processes of the computer in which the data aremaintained-can provide some assurance that the data aresufficiently reliable. Examples of system controls are limits onaccess to the system and edit checks on data entered into thesystem. Controls can reduce, to an acceptable level, the risk thata significant mistake could occur and remain undetected anduncorrected. Limit the review to evaluating the specific controlsthat can most directly affect the reliability of the data inquestion. Choose areas for review on the basis of what is knownabout the system. Sometimes, you identify potential system controlproblems in the initial steps of the assessment. Other times, youlearn during the preliminary assessment that source documents arenot readily available. Therefore, a review of selected systemcontrols is the best method to determine if data were enteredreliably. If needed, consult information system auditors for helpin evaluating general and application controls.Using what you know about the system, concentrate on evaluatingthe controls that most directly affect the data. These controlswill usually include (1) certain general controls, such as logicalaccess and control of changes to the data, and (2) the applicationcontrols that help to ensure that the data are accurate andcomplete, as well as authorized.The steps for reviewing selected system controls aregain a detailed understanding of the system as it relatesto the data andidentify and assess the application and general controlsthat are critical to ensuring the reliability of the data requiredfor the engagement.In some situations, it may not be feasible to perform anyadditional work,Using Data offor example, when (1) given a shorttime frame (too short for a complete assessment), (2) originalcomputer files have been deleted, or (3) access to Reliabilityneeded documents is unavailable. See section 9 for how toproceed.Section 9: Making the Final AssessmentDuring the final assessment, you should consider the results ofall your previous work to determine whether, for your intended use,the data are sufficiently reliable, not sufficiently reliable, orstill undetermined. Again, remember that you are not attesting tothe reliability of the data or database. You are only determiningthe sufficiency of the reliability of the data for your intendeduse. The final assessment will help you decide what actions to take(see figure 7).Figure 7: Making the Final AssessmentSource: GAO.The following are some considerations to help you decide whetheryou can use the data:The corroborating evidence is strong.The degree of risk is low.The results of additional assessment (1) answered issuesraised in the preliminary assessment and (2) did not raise any newquestions.The error rate, in tracing to or from source documents,did not compromise reliability.In making this assessment, you should consult with appropriatetechnical specialists.You can consider the data sufficiently reliable when youconclude the following: On the basis of the additional work, aswell as the initial assessment work, using the data would notweaken the analysis nor lead to an incorrect or unintentionalmessage. You could have some problems or uncertainties about thedata, but they would be minor, given the research question andintended use of the data. When your final assessment indicates thatthe data are reliable, use the data.Sufficiently Reliable DataNot Sufficiently Reliable DataYou can consider the data to be not sufficiently reliable whenyou conclude the following: On the basis of information drawn fromthe additional assessment, as well as the preliminary assessment,(1) using the data would most likely lead to an incorrect orunintentional message and (2) the data have significant orpotentially significant limitations, given the research questionand intended use of the data.When you determine that the data are not sufficiently reliable,you should inform the requester that sufficiently reliable data,needed to respond to the request, are unavailable. Remember thatyou-not the requester-are responsible for deciding what data touse. Although the requester may want information based oninsufficiently reliable data, you are responsible for ensuring thatdata are used appropriately to respond to the requester. If youdecide to use the data for the report, make the limitations of thedata clear, so that incorrect or unintentional conclusions will notbe arrived at. Appropriate team management should be consultedbefore you agree to use data that are not sufficientlyreliable.Finally, given that the data you assessed have seriousreliability weaknesses, you should include this finding in thereport and recommend that the agency take corrective action.Data of Undetermined ReliabilityYou can consider the data to be of undetermined reliability whenyou conclude the following: On the basis of the information drawnfrom any additional work, as well as the preliminary assessment,(1) use of the data could lead to a incorrect or unintentionalmessage and (2) the data have significant or potentiallysignificant limitations, given the research question and theintended use. You can consider the data to be of undeterminedreliability if specific factors-such as short time frames, thedeletion of original computer files, and the lack of access toneeded documents-are present. If you decide to use the data, makethe limitations of the data clear, so that incorrect orunintentional conclusions will not be arrived at.As noted above in the case of not sufficiently reliable data,when you determine that the data are of undetermined reliability,you should inform the requester-if appropriate-that sufficientlyreliable data, needed to respond to the request, are unavailable.Remember that you-not the requester-are responsible for decidingwhat data to use. Although the requester may want information basedon data of undetermined reliability, you are responsible forensuring that appropriate data are used to respond to therequester. If you decide to use the data in your report, make thelimitations clear, so that incorrect or unintentional conclusionswill not be arrived at. Appropriate team management should beconsulted before you agree to use data of undeterminedreliability.Section 10: Including Appropriate Language in the ReportSufficiently Reliable DataIn the report, you should include a statement in the methodologysection about conformance to generally accepted government auditingstandards (GAGAS). These standards refer to how you did your work,not how reliable the data are. Therefore, you are conforming toGAGAS as long as, in reporting, you discuss what you did to assessthe data; disclose any data concerns; and reach a judgment aboutthe reliability of the data for use in the report.Furthermore, in the methodology section, include a discussion ofyour assessment of data reliability and the basis for thisassessment. The language in this discussion will vary, depending onwhether the data are sufficiently reliable, not sufficientlyreliable, or of undetermined reliability. In addition, you may needto discuss the reliability of the data in other sections of thereport. Whether you do so depends on the importance of the data tothe message.Present your basis for assessing the data as sufficientlyreliable, given the research questions and intended use of thedata. This presentation includes (1) noting what kind of assessmentyou relied on, (2) explaining the steps in the assessment, and (3)disclosing any data limitations. Such disclosure includestelling why using the data would not lead to an incorrector unintentional message,explaining how limitations could affect any expansion ofthe message, andpointing out that any data limitations are minor in thecontext of the engagement.Present your basis for assessing the data as not sufficientlyreliable, givenNot Sufficientlythe research questions and intendeduse of the data. This presentation should include what kind ofassessment you relied on, with an explanation of the steps in theassessment.Data of Undetermined ReliabilityIn this explanation, (1) describe the problems with the data, aswell as why using the data would probably lead to an incorrect orunintentional message, and (2) state that the data problems aresignificant or potentially significant. In addition, if the reportcontains a conclusion or recommendation supported by evidence otherthan these data, state that fact. Finally, if the data you assessedare not sufficiently reliable, you should include this finding inthe report and recommend that the audited entity take correctiveaction.Present your basis for assessing the reliability of the data asundetermined. Include such factors as short time frames, thedeletion of original computer files, and the lack of access toneeded documents. Explain the reasonableness of using the data, forexample: These are the only available data on the subject; the dataare widely used by outside experts or policymakers; or the data aresupported by credible corroborating evidence. In addition, make thelimitations of the data clear, so that incorrect or unintentionalconclusions will not be drawn from the data. For example, indicatehow the use of these data could lead to an incorrect orunintentional message. Finally, if the report contains a conclusionor recommendation supported by evidence other than these data,state that fact.Glossary of Technical Termsaccuracy. Freedom from error in the data.completeness. The inclusion of all necessary parts orelements.database. A collection of related data files (for example,questionnaire responses from several different groups of people,with each group's identity maintained.)data element. An individual piece of information that hasdefinable parameters, sometimes referred to as variables or fields(for example, the response to any question in a questionnaire).data file. A collection of related data records, also referredto as a data set (for example, the collected questionnaireresponses from a group of people).data record. A collection of related data elements that relateto a specific event, transaction, or occurrence (for example,questionnaire responses about one individual-such as age, sex, andmarital status).source document. Information that is the basis for entry of datainto a computer.GAO's MissionThe General Accounting Office, the investigative arm ofCongress, exists to support Congress in meeting its constitutionalresponsibilities and to help improve the performance andaccountability of the federal government for the American people.GAO examines the use of public funds; evaluates federal programsand policies; and provides analyses, recommendations, and otherassistance to help Congress make informed oversight, policy, andfunding decisions. GAO's commitment to good government is reflectedin its core values of accountability, integrity, andreliability.Obtaining Copies of GAO Reports and TestimonyThe fastest and easiest way to obtain copies of GAO documents atno cost is through the Internet. GAO's Web site (www.gao.gov)contains abstracts and fulltext files of current reports andtestimony and an expanding archive of older products. The Web sitefeatures a search engine to help you locate documents using keywords and phrases. You can print these documents in their entirety,including charts and other graphics.Each day, GAO issues a list of newly released reports,testimony, and correspondence. GAO posts this list, known as"Today's Reports," on its Web site daily. The list contains linksto the full-text document files. To have GAO e-mail this list toyou every afternoon, go to www.gao.gov and select "Subscribe todaily E-mail alert for newly released products" under the GAOReports heading.Order by Mail or PhoneThe first copy of each printed report is free. Additional copiesare $2 each. A check or money order should be made out to theSuperintendent of Documents. GAO also accepts VISA and Mastercard.Orders for 100 or more copies mailed to a single address arediscounted 25 percent. Orders should be sent to:U.S. General Accounting Office 441 G Street NW, Room LMWashington, D.C. 20548To order by Phone: Voice: (202) 512-6000 TDD: (202) 512-2537Fax: (202) 512-6061Contact:To Report Fraud, Web site: www.gao.gov/fraudnet/fraudnet.htmE-mail: fraudnet@gao.govFederal Programs Automated answering system: (800) 424-5454 or(202) 512-7470Jeff Nelligan, managing director, NelliganJ@gao.gov (202)512-4800Public AffairsU.S. GeneralAccounting Office, 441 G Street NW, Room 7149Washington, D.C. 20548Presorted Standard Postage & Fees Paid GAO Permit No.GI00United States General Accounting Office Washington, D.C.20548-0001Official Business Penalty for Private Use $300Address Service Requested